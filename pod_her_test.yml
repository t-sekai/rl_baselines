apiVersion: v1
kind: Pod
metadata:
  name: tsc003-her-test
  namespace: ucsd-haosulab

spec:
  containers:
    - name: work-container
      image: tsekai/reverserl_her:latest # docker image
      # imagePullPolicy: Always
      command:
            - bash
            - -c
            - |
              export XLA_PYTHON_CLIENT_PREALLOCATE=False # turn on to dynamic allocate GPU memory
              export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mjpro150/bin
              export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco200/bin
              export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/root/.mujoco/mujoco210/bin
              export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib/nvidia-430

              git clone https://github.com/t-sekai/rl_baselines.git
              cd rl_baselines
              pip install -e .[test]
              echo "done setup"
              sleep infinity
      resources:
        requests:
          cpu: "5"
          memory: "10Gi"
          nvidia.com/gpu: "1"
        limits:
          cpu: "5"
          memory: "10Gi"
          nvidia.com/gpu: "1"
      volumeMounts:
        - name: tsc003-fast-vol
          mountPath: /tsc003-fast-vol
  volumes:
    - name: tsc003-fast-vol
      persistentVolumeClaim:
        claimName: tsc003-fast-vol
  restartPolicy: Never
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: nautilus.io/group
              operator: In
              values:
                - haosu
            - key: nvidia.com/gpu.product
              operator: In
              values:
                - NVIDIA-GeForce-RTX-2080-Ti